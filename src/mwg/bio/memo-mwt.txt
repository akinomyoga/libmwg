
-------------------------------------------------------------------------------
  ToDo
-------------------------------------------------------------------------------

2017-04-20

* 実は itape という形にしている意味は無いのではないか。

  duck typing できる様にするというので十分な気がする。
  つまり必要なメンバが存在していれば itape に代入できるという様にする。
  これによる変更は如何程だろうか。

2017-04-18

* tape_head::memset

  これは一般化して write(T const& value, std::size_t count) にした方が良いのでは。

* sparse files に対応する?

  現状では sparse files の事は考えずに常にゼロ埋めする実装という事にする。
  ファイル末尾を超えた fseek が返す値と errno の関係などを確かめる必要がある。

* allocate で大きな領域を確保した時、

  誰が fat_write を実行するのかという問題が生じる。
  allocate_block なのか、allocate なのか。
  更に具体的に block_chain を割り当てるのか割り当てないのかも。
  未割り当ての場合にはゼロが埋まっていると考えて、
  初めて書き込みが行われる時に block を割り当てるという考え方と、
  高確率で使うという事が分かっているのだから最初から割り当てるという考え方がある。
  よく考えてみると fat に対する書き込みは最初に一括で割り当てても減る訳ではない。
  従って、遅延割当でも良いのではないかという気がする。

  allocate_block で fat_write を実行する様にする場合は、
  後で実際に使用する値で再び fat_write をする事が分かっているので無駄だ。
  しかし、ここで fat_write を省略すると呼び出し元で fat_write を忘れると不整合を生じる。
  ところで突然プログラムが終了するなどの事故が起こった場合はどうなるだろう。
  使用・未使用は実際の状況から読み込み時に判定するので、
  ファイル自体に不整合が生じるという事はない様に思う。
  一つ、何処からも参照されないブロックが発生するという可能性はあるが、
  それは参照を追跡して mark&sweep する事にすれば簡単に除去できる。
  結局のところ dangling ポインタが発生しないような順序で読み書きすれば良いだけである。

2017-04-16

* 古い実装を調べて整理を行う。

  以前の実装ではいきなり複雑に実装しすぎていた様な気がする。
  もっと階層的に実装しても良いのではないかという気がする。
  つまり、様々なサイズのデータを allocate する階層と、
  ファイル構造を管理する部分である。
  ファイル構造の代わりに汎用のデータベース的な構造や、
  細かいメモリ領域を割り当てるヒープの様な使い方もしたいからである。

  v しかし階層に分ける事によって何か非効率が生じたりしないだろうか。
    これは具体的にどの様な設計にするかに依存する様に思う。
    通常ファイル構造を管理する場合には inode の領域とデータの領域に分ける。
    inode の数は可変にしたいとすると inode の領域はブロックに跨って配置しなければならない。
    結局、一つの長い領域を作って其処に配置するという形にする必要がある。
    従って階層に分けなくても元から inode データも管理しなければならなかった。

    結論: 階層に分ける事によって非効率になるという事はない気がする。

  v 古い実装でのブロック使用方法はどの様になっていただろうか。

    #D0001 の内容をまとめる。

    - 基本のブロックサイズは 1KB である。
      比較的小さめだがこれは小さなデータの断片を大量に使用する事を想定しての事である。
      然し今確認した所 ext4 でも 1024 なので案外普通の大きさなのではないか。

    - 256 ブロック毎に面をなす。
      各面の最初のブロックは指示ブロックと呼び、4B x 256 個の整数を以てその面の地図を描く。
      整数が 256 で割り切れない場合、対応するブロックの次のブロック番号を表す。
      整数が 256 で割り切れる場合は、特別な意味を持つ ID である。
      例えば "未使用" / "末端ブロック" / "ルートブロック" / "miniFAT/heap用" など。

    - miniFATs/Heap はそれぞれテーブルとデータからなる。

    - ヒープのメモリ領域は

      struct HRange { int prev, next, offset, length; };

      の配列によって管理する。各 HRange が各メモリ領域に対応する。
      prev, next は次の使用中 HRange への参照を保持する。
      HRange は一度割り当てたら基本的に削除できない。

  v ブロックサイズ 1024 と 32bit ブロックインデックスで充分かということ。

    ここで論理的な最大サイズが決まる。2^32 x 1024 だと 4TB になる。
    幾らデータベースにするとしても単体でここまで巨大になる様なら、
    もっとちゃんとした仕組みを使う様に変更したほうが良い。
    なので十分である。

    % また位置を一つの整数で表そうと思うと 4GB に制限される。
    % ただ位置を一つの整数で表す事はあるのだろうか。
    % そういう種類の情報はデータの指定とデータ内の offset の組で表されるべきである。
    % そしてデータの指定は何らかのテーブル上の index で指定される筈である。
    % 絶対位置で指定しているとブロックを再配置できなくなってしまうからである。

    ところで 8B で区切るとどうなるだろうか。
    面の大きさは 1024/8 = 128 ブロックになる。1/128 を管理用データが占める。
    面の大きさは 128KB である。
    一方で論理的な最大サイズは 2^64 x 1024 = 16ZB になる。

    或いは 4096/8 = 512 にするとどうなるか。
    1/512 が管理用データになり、面は 2MB のサイズになる。

  v ヒープはどの様に設計しようか。

    以前の実装計画ではデータの長さに応じて
    (1) block に直接割り当てる (FAT)
    (2) mini FAT 256 bytes で割り当てる
    (3) mini FAT 64 bytes で割り当てる
    (4) 愚直 heap で割り当てる
    という具合に分けていたが、全体を heap と考えて、
    heap のアルゴリズムで確保してしまえば良いような気がする。

    heap のアルゴリズムで簡単なのは
    1 2 4 8 ... 512 bytes (10種類)
    のメモリ領域ごとに配列を作ってしまうというのである。
    様々な種類のデータを使うと 10KB 無駄に消費する事になるが、
    まあこれは気にならない大きさだ。

    heap 内への参照はどの様に取り扱うべきか。
    長さが分かっていればどの配列に格納されているかも分かる筈である。
    その配列の中の番号で良いだろう。
    というか思ったのだけれど 1-4 bytes に関しては配列中の番号とはせずに
    其処に直接データを書き込むというので良い気がする。

    では使用していない領域のテーブルは何処に保持するべきだろうか。
    a これを別のブロック鎖に格納しようと思うとまた無駄にメモリを食う。
    b 各配列に FAT と同じように特別な位置を設定して、
      そこに bit pattern で使用・未使用を記録するようにするのはどうだろう。
      然しそうすると "次の未使用な領域" を見つけるのが困難になる。
    c bit pattern ではなくて index で管理するという方法にするのだろうか。
      だとすると結構領域を食う様な気がする。1-4 bytes は配列に格納しないとして、
      8 byte の領域毎に 4B の index 情報を消費する。
    うーん。まあ c の方法が現実的だろうか。
    でも実際の所、未使用領域を管理するだけが目的である…。

    todo: メモリ領域のリストの形式は [{長さ,番号}]
      この配列内で未使用の要素はどの様に管理したら良いだろうか。

      a 一つの方法は未使用の要素を以てリストを作るという方法である。

      b もう一つの方法は未使用の要素を compaction して除いてしまうという方法である。
        compaction する為には外部からこの配列要素への参照があってはならない。
        内部で全て完結していなければならないという事になる。
        しかしそれは難しい。

      c もう一つの方法は [{ID,長さ,位置}] にするという方法である。
        配列は ID について昇順になる様に管理する。
        外部からの参照は ID を用いて行う。

        これだと外部からアクセスを行う度に ID の二分探索が必要になる。
        外部からのポインタは {ID, compaction_version, hindex} の形式にすれば良い。
        compaction_version が一致している限りはキャッシュした hindex 番目にデータがあると思って良い。
        compaction を実行したら配列の compaction_version をインクリメントする様にすれば良い。
        compaction は滅多に行われないので気にはならないだろう。
        ただ compaction_version を毎回チェックしなければならないという問題は生じる。

        或いはグローバルな compaction はファイルを開く前にしか実行できないという様にするか。
        それだとやはり不便なのでファイル全体で一つの compaction_version を管理するのが良いだろう。

  v というかそもそも FAT 形式にする必要はあるのか。

    ext2 - Wikiepedia (English) を見ると、
    ブロック番号はリストになっているのではなくて、
    inode 内部に確保されたリストで管理されている。
    つまり inode はブロックを参照する固定長の配列を内部に持つという事である。
    (これは FAT 中のファイルでも同じだったかもしれない。)

    しかし一方で、ブロック一覧を可変長のリストにするという手もある。
    その為にはブロックの連鎖を定義する前に可変長のデータを扱える仕組みが必要である。
    つまり鶏が先か卵が先かという問題になってしまう。
    結局 FAT を使用してブロックの連鎖を定義し、
    同時に実際のユーザデータではブロック一覧も並用して速度を向上する
    という使い方が良いのではないだろうか。

    [結論]

    うーん。色々考えると
    1 FAT による連結ブロック
    2 Heap/FAT によるメモリ領域
    3 ファイルシステム etc
    などの様な階層構造にするのが良さそう。

  v ファイルの形式は mwt という名前になっているがこれはどうだろう。
    元々は恐らく myoga binary tree とかそんな様なものだろう。
    しかし使用方法や階層に応じて異なる名前にした方が良いかもしれない。

    例えば level 2 の場合には .mwheap とし、
    level3 filesystem は .mwfs とし、
    level3 database は .mwdb とするなど。
    .bioheap, .biofs, .biodb の方が良いかもしれない。


* 特定のファイル形式を取り扱うヘッダ

  この様な感じにファイルを増やしていくと命名が面倒になる気がする。
  今のうちにファイル形式に対応するヘッダ・ソースの名前の付け方を考えるべきかもしれない。

  | 例えば
  |   mwg/bio/file-ttx.h
  |   mwg/bio/file.ttx.h
  |   mwg/bio/file_ttx.h
  |   mwg/bio/format-ttx.h
  |   mwg/bio/ttxfile.h
  |   mwg/bio/ttx-file.h
  |
  | 案1
  |   mwg/bio/file-ttx.h
  |   mwg/bio/file-mwheap.h
  |   mwg/bio/file-mwfs.h
  |   mwg/bio/file-mwdb.h
  |
  | 案5
  |   mwg/bio/ttxfile.h
  |   mwg/bio/mwheapfile.h
  |   mwg/bio/mwfsfile.h
  |   mwg/bio/mwdbfile.h

  案1 が良い気がする。


-------------------------------------------------------------------------------
  Experimental2 Memo
-------------------------------------------------------------------------------

  以下は古い実装の記録である。

namespace mwg{
namespace mwt_format_detail{

  /* version 1 概要:


  ■ブロック構造に関しては #D0001 を参照。

  ■ファイル内ポインタの種類
    * PtrB
      ブロックへのポインタ
      ```
      struct PtrB{
        int offset; // ブロック番号
        int length;
      };
      ```
    * PtrP
      属性内容へのポインタ
      - データが 4kB を越える場合、ブロック番号で示す
      - データが 1kB を越える場合、fat256 セル番号で示す
      - データが 64B を越える場合、fat64 セル番号で示す
      - それ以外の場合、その場に記録する
      ```
      struct PtrP{
        int length;
        int offset; // 長さによって解釈が変わる
      };
      ```
    * PtrN
      ノード内容記録用のポインタ
      - データが 4kB を越える場合、ブロック番号で示す
      - データが 1kB を越える場合、fat256 セル番号で示す
      - データが 64B を越える場合、fat64 セル番号で示す
      - それ以外の場合、Heap 内での offset で示す
      ```
      struct PtrN{
        int offset; // 長さによって解釈が変わる
        int length;
      };
      ```

  ■木構造のノードの種類

    + ノードのデータ
      ```
      enum NodePropType{
        NPT_DATA='D', // DATA: ファイル内容
        NPT_FILT='F', // FILT: ファイル内容に対するフィルタ
        NPT_MIME='M', // MIME: ファイル内容の形式を指定する MIME type
        NPT_LIST='L', // LIST: 子ノード配列
        NPT_TIME='T', // TIME: タイムスタンプ
        NPT_FLAG='A', // FLAG: フラグ rwx ash
        NPT_PROP='P', // PROP: 一般属性・ストリーム
      };
      struct NodeData{
        char name[1]; // null terminated
        NodeProp properties; // 複数続く
      };
      struct NodeProp{
        byte ptype;
        char content[1];
      };
      struct NodePropProp{
        byte ptype;   // =NPT_PROP
        char name[1]; // null terminated
        PtrP content;
      };
      ```

  ■ノードの実装
  * ノードの種類
    ノードの種類は明確には区別しない事にした。
    ノードプロパティに制限を掛けると、
    ディレクトリやファイルとしての使い方をする事が出来る。

    + ディレクトリ
      LIST: 任意の子ノード参照の配列を有する
      TIME:
      FLAG: タイムスタンプや属性フラグを有する
      PROP: その他の属性を持ちうる
    + ファイル
      DATA: 比較的大きめのデータを有する
      FILT:
      MIME: フィルタやデータの MimeType 等の情報を持つ
      TIME:
      FLAG: タイムスタンプや属性フラグを有する
      PROP: その他の属性を持ちうる
    + 要素 (XML要素など)
      LIST: 子ノード参照配列を有する場合がある
      PROP: その他の配列を持ちうる

  * データ記録形式とサイズ評価
    <name key="value" /> (PROP 一個を持つ場合)
      sizeof(name)+1 +1 +sizeof(key)+1 +4+sizeof(value)
      7+name+key+value == 19

  * ノードの実装について
    1. ノードのデータをどの様に保持するか
      これまでの考えだと、ノード中の長いデータは別のストリームに記録し、
      短いデータはそのまま埋め込むという事になる。

      これは、ノードデータの書き換えなどに対して適当だろうか。
      a. ファイルデータの書き換えに対しては、
        ノードデータを全体的に書き換えるという事はせずに、
        長さのデータだけ変更すると言うようにしたいので、
        之迄の考えの様に、他のストリームに記録するという方向で問題ない。
      b. 属性値などに関しては、
        之迄の考えでは、長い場合には他のストリームに記録して、
        そうでない場合には、中に埋め込むという事である。

        * そもそも、属性値は tape として編輯する事を想定していないので、
          態、他のストリームに記録する必要があるのか?
          + 然し、「ファイルのサブストリーム」として利用するやり方もあるので、
            ストリームに記録したいという事もあるだろう。
            - では、属性値は別にサブストリームという名前の項目を作ればよいのではないか?
              + 色々データの種類を作りすぎると検索などの処理が面倒である。
                できるだけ余り沢山の種類のデータは作りたくない
          + 属性値でもアイコンのデータなど大きなデータを保持したい事はある。
            その様な大きなデータの場合 tape としての編輯が必要ないとしても、
            直接埋め込む形で保存しているとノードの僅かな書き換えに対して、
            初めから全て書き直すなどの処理が必要になり、
            重くなってしまうのでは?
            - 然し、xml 等の場合には、実際にその様な重いと思われる処理を実行している。
              それ程問題にはなっていないようであるが?
              + でも、xml と違ってヘビーな使い方をしたくなるかも知れない。
        * 他のストリームにも保存する場合に実装で気を付けなければならない点は?
          + ノードを削除する場合に、ちゃんと属性値に対応するストリームも解放する事
    2. ノード一部書き換えに適したノード表現
      ノードは現在の仕様では「データを完全に読み取って、
      それから、書込は完全に初めからバイナリに変換する」という想定になっている。
      然し、それは、例えば「アクセス日時だけを変更したい」等という場合には、
      酷く無駄な処理を行う必要が出て来る事を意味する。

      * 頻繁に書き換えが発生するだろうと思われる定型データと、
        余り書き換えられない・使用されない・サイズが可変なデータを区別して保存する

        定型データは前の方に配置する事にして、
        可変サイズデータは後の方に配置するようにするなど。
        - これは微々たる効果しか生まないのでは?
          できるだけファイル名などは初めの方に配置したい。
          (ファイル名は可変長である)
        - 実装が面倒臭い

        頻繁に書き換えられる定型データの書き換えに際しては、
        全体を初めから書き直すのではなく、当該部分だけ書き換える事によって
        更新を実行する事ができる。

      * 属性値の読込が起こる迄、バイナリ→データへの変換を遅延する
        更に、属性値の書込がない限り、データ→バイナリ列はせずに、
        既存のバイナリ列を流用して書き込む

        その為には、ノードの変更時には
        1 既存のストリームを残したまま、それとは別の新しいストリームを作成する。
        2 既存のストリームを読みながら新しいストリームに書き込む
        3 既存のストリームを削除して、新しいストリームをノードから参照するようにポインタを書き換える。
        という形態を取る必要がある。

        ノードインスタンスの構造は模式的には以下のような物になる。
          struct attr_t{
            tape binary;
              // データストリームへの参照、または、ノードのサブシーケンス
            attr_data data;
              // 属性のデータ表現
              // * 例えば日時を記録する構造体
              // * 例えばファイル内容を記録するデータポインタ
              // * 例えば std::vector<NID>
              // * 例えば属性名+(ストリーム/std::vector<byte>)
            bool fDataRead;
              // 属性のデータが binary から復号されたかどうかを見るフラグ
              // これは、binary のパースを遅延する為に使用する。
              // 必ずしも data の内容を参照しないのにデコードしても仕様がないので。
              // * data メンバを参照する前に確認する
            bool fDirty;
              // 属性値が変更されたかどうかを見る為のフラグ
              // data が binary から読み取った物に一致している場合に false
              // data から binary に戻す必要がある場合に true
              // * data メンバに変更を加える時に true を設定する
              // * ファイルにノードを書き込む時に参照し、
              //   true であれば data からデコードしながら書き込む
              //   false であれば binary から読込ながら書き込む

            static const bool is_size_variable;
              // binary 表現でのデータサイズが変化しうるかどうかを表すフラグ
              // * ノードの属性値が全て fDirty⇒!is_size_variable
              //   を満たしているならば、ノード変更は元のストリームを弄るだけでよい。
              //   具体的には fDirty な物だけ binary 部分を書き換えれば良い。
              //  →更に、型に対する整数ではなくて、
              //    現在の状態に対応してサイズ変化を伝えるメソッドにした方が良い。
              //    特に新しくノードに追加した属性がある場合などにも対応できる。
              //    →或いは、サイズ変化と言わず「現在のデコード結果の長さ」を
              //      返す様にした方が応用が利くかも知れない。
            void update(fixedlen_tape) const;
              // 上記の一部書換用のメソッドとして update を提供する。
          };



  ■ 既知の問題点
  + 文字コードはどうするか
    ノード名などに文字列が使用されるが、それに使用する文字コードをどうするかは問題の一つである。
    a 文字コードを可変にする
      これが一番汎用性が高い。然し、実装が面倒である。
      1 mwt ファイル単位で文字コードを設定する
        X これだとファイルのマージなどの際に面倒である。
          (とは言っても、面倒なだけでそれ程問題になる訳でもない。)
      2 文字列単位で文字コードを設定する
        X これだと文字列を埋め込む度に、文字コード指定をしなければならず、
         ファイルサイズの無駄である。
      3 1+2 デフォルトの文字コードを mwt ファイル単位で指定する
        文字列がデフォルトと異なる文字コードを使用している際には
        特別に文字コードを指定を加える。
        X デフォルト文字コードを使用するか、特別に文字コードを指定するかを判別する為に
          1bit の情報を付加しなければならない
    b ASCII だけに限る
      O プログラム内部で使用するだけに留めるならば、これで充分である。
      X 然し、ノードをユーザが入力するデータに合わせて作成したい場合は、
        当然日本語なども使用したくなるので、この方法では良くない。
    c UTF-8 決め打ち
      これが一番現実的かも知れない。
      O 特に null 文字は単にバイト毎に 0 かどうかを確認すれば良いだけである。
      △文字コード変換のコードを書かなければならない
        codecvt は面倒くさい…というか書いても何でそれでいいのか良く分からない…。
    d 処理系依存の文字コード決め打ち
      O 一番実装が簡単なのがこれである。
      X これだと或る処理系で作成したファイルを他の処理系で使用できないことになる。
        エンディアンネスを LE に固定している意味がない。
  + ファイルサイズの問題
    ファイルサイズが大きくなってくると色々と問題が生じうる
    X 先ず、ファイルフォーマットの都合上上限ファイルサイズがある。
      特に
      ・各ストリームの上限サイズ　... 4GB (length 制限)
      ・Fat256 の上限サイズ ... 4GB (length 制限が無くても 1TB)
      ・Fat64 の上限サイズ ... 4GB (length 制限が無くても 256GB)
      a Fat256/Fat64 の上限サイズを拡大するか?
        length のビット幅を拡張すれば 1TB/256GB にまで拡張出来る。
        全ストリームで拡張する必要はないが、
        Fat256/Fat64 ストリームだけ特別に拡張する事もできる。
      b 全てのストリームの offset/length 表現を 64bit に拡張するか?
        因みに、64bit あれば 16EiB 迄堪えうる。
      ■現状では上限に達した時の動作を記述していない。
        空きブロック探索で無限ループに陥ったり、
        既にあるデータを上書きしたりする危険性がある。
    X 更に、差分バックアップなどの際に丸ごと全部コピーしなければならなくなる。
      少しの変更を加えるだけで全てバックアップしなければならなくなるのは損である。
      →mwt ファイル専用の差分バックアップを実装するという手もある。□
        新旧両方に変更日時があって、更新されていない事を確認出来ればスキップする事が出来る。
  + 同時編集・同期
    →サブストリーム自体を複数の場所から同時に触る事ができるように、
      同期の仕組みを作成する必要がある。
      特に、サブストリームを操作する為のクラス celltape は
      ローカル変数の std::vector にブロック表を保持しているが、
      これの内容を複数のアクセス元の間で共有出来るようになっていないと行けない。
      その方法としては以下のような案が考えられる。
      a これのメモリ領域を複数の使用場所で共有する
        X 特に、アクセス元が複数のプロセスに分かれて存在する事もあるので、
          プロセス間の共有メモリを確保する必要性が生じる。
          これの実装は面倒である。
      b std::vector ローカル変数の使用を止めて、ファイルの中身から毎回ブロック表を再構成するか
        O 実装は簡単である
        X 動作が遅い
          一々シークする度に初めからブロックポインタを辿っていかなければならない。
      c ブロック表自体を一時的に .mwt ファイル内のストリームに作成する
        このブロック表専用ストリームは、ブロック表を使用せずにアクセスする
        O b の方法よりは高速である。
        X それに a 程実装が面倒という訳でもない。
      d ブロック表自体を別の一時ファイルの上に作成して、それを参照する
        O 実装がとても簡単である。
        X 一時ファイルを作成しなければならないのが欠点である。
          一つのファイルの中で閉じていた方が綺麗である。
      e 或いは、全く異なる解決方法として「mwtfile アクセス用だけのプロセスを作成する」と言う手もある。
        他のプロセスから mwtfile にアクセスしたければ、
        そのプロセスと通信する事によって間接的にアクセスをするのである。
        実装は大変 (OS 依存) ではあるが、
        データベースのプログラムなどでも採用されている様に之が一番賢明なのかも知れない。
      f ノード一覧表と MiniFATデータだけは d の方法で管理し、
        他のストリームはロックして使用するという手もある。
        この方法なら、一時ファイルも高々数個で済む。

    ×また、根本的な問題として
      複数のプロセスで w アクセスで同時にファイルを開く事ができるのか?
      というのもある。これは、OS によってはできない可能性がある。
      また、他のプロセスで書き込んだ内容を正確に読み取る為には、
      アクセスの度に flush を実行しなければならない。

      →ちょっと調べてみた所、やはり OS によるだけでなく、
        fopen を実装しているライブラリによっても、
        ファイルをロックしてしまうかどうかが異なるという事が分かった

    同期の方法は OS によって異なる方法を使用する必要がある。
    a UNIX では POSIX セマフォを用いて同期を行う。
      但し Ctrl+C とかで終了した場合、セマフォが中途半端な状態で残ってしまう為、
      シグナルハンドラを適切に指定するようにする。
    b Windows では簡単に Mutex を使うという事でよい
    c POSIX では
      O_CREAT|O_EXCL で開く事でファイルを作成・ロックできる
      http://en.wikipedia.org/wiki/C1X の fopen("hoge.lock","x")
      http://en.wikipedia.org/wiki/File_locking#Lock_files

    [保留]
  + flush を避ける為に seek の呼出を if(tell!=size)seek の形にしている
    然し、これは、ftape 側の実装の問題であり、
    ftape 以外の例えば memory_tape に対しては seek は直接呼び出しても構わない。

    要するに tell!=size のチェックは ftape の中で行うべきである。
    因みに、cached_tape の seek の中でも flush が必要になるので、同様である。
  ■計画
  * mwg.RemoteFs に統合する
  * accessor を増強する
    型毎に簡単に読込・書込メソッドを定義できる様にする。
      グローバルに
        void write_data(head&,const S&);
        template<typename Fmt>
        void write_data(head&,const S&,const Fmt&);
      のオーバーロードを定義させるようにするか、或いは、クラス内に
        static void mwg_write_data(head&,const S&);
        template<typename Fmt>
        static void mwg_write_data(head&,const S&,const Fmt&);
      を定義させるかする。
  * tape 増強
    + class subsequence_tape;
    + functor_t operator|(const itape&,const itape&);
      オブジェクトの寿命が微妙
        (mwg::io::ftape("src.dat","rb")|mwg::io::ftape("dst.dat","wb"))();
        は大丈夫であるが、
        functor_t f=mwg::io::ftape("src.dat","rb")|mwg::io::ftape("dst.dat","wb");
        f(); // ここに来た時点で二つの ftape は消えている。
        は駄目。

        a というか、itape はコピーに対しても大丈夫な様にするべき?
          + そうすれば head のコンストラクタに直接突っ込む事が出来る?
            →現在の初期化方法もそのままにするのだと、
              head の初期化方法によって扱いを色々に変えなければ行けない。
              もし、head に直接入れる事が出来る様にするのであれば、
              std::shared_ptr 等に入れるのが良い。
          - その時に問題になるのは
            - FILE* 等のリソースの寿命管理
              std::shared_ptr に全部込める?
          + コピーされても良い様に設計しておき、
            コピーされたくない種類のストリームの場合には
            コピーコンストラクタ/コピー演算子を封じておく
        b 或いは、スマートポインタに入れた状態での操作をサポートする?
          でも、これは使用時に使用状況に合わせて
          スマートポインタに入れなければならなかったり、
          入れなくても良かったりして余り良い実装とは言えない。
          直感的でない使い方をしなければならない。
        c tape 専用のコンテナクラスを作成し
          常にインターフェイスはそのコンテナクラス
          →結局 shared_ptr を使えば良いだけでは?
            つまり、常にスマートポインタに入れて使いましょうと言う事。
          →常に scoped_ptr を使用するという方が良いかも?
            変に共有して複数の場所から読み書きすると変な事が起こる。
            でも、良く考えたら mwtfile は
            itape* を複製しまくって複数の所から読み書きを実行するようになっている。
        d 基本的にコピーに対しても大丈夫な様に設計しておき、
          コピー出来ない物の為に shared_tape を実装する事にした

      - operator| で functor_t を返さずに直ぐに処理を行ってしまって良い。
        functor_t にする為には唯単に lambda を使用すれば良いだけの事。

    + operator| 序でに、filter も実装
      + Base64Encode
      + Base64Decode ■
      + Ascii85Encode ■
      + Ascii85Decode ■
      + HexEncode
      + HexDecode
      + iconv adapter ■
      + ICU cnv adapter ■

  */
}
}


-------------------------------------------------------------------------------
  Done
-------------------------------------------------------------------------------

2017-04-19

* hbitmap による未使用領域の探索は遅いのではないか。

  特に割当領域の数が少ない内は良いが、
  何百万という単位になってくると問題になるはずだ。
  それよりは未使用のインデックスのリストを作って管理した方が良いのではないだろうか。

  そもそも hbitmap を作成したのは
  最初に読み取った時に使用している領域・していない領域を調べる為であった。
  初期化が終わったらこの形式である利点はないのではないだろうか。

  →これは heap_free_cells による実装に切り替えた。

2017-04-16

* mwt-experimental2.txt のブロック定義 [#D0001]

  1.ファイル全体の構造は 1kB 単位のブロックが並んだ構造になっている。
    一つ一つのブロックには、ファイルの先頭から順にブロック番号が付けられる。
    一番初めのブロックの番号は 0 になり、次のブロックは 1 に、その次は 2... という具合になる。

    個々のデータストリームは、ファイル内で、複数のブロックに分散されて記録される。
    256 で割り切れる番号のブロック (■) は特別なブロックであり、
    それ以外の普通のブロック (□) がどのデータを持っているかを示す為に使用される。

    ■□□□□□□□□□□□□□□□
    □□□□□□□□□□□□□□□□
    □□…
            … (□×255 個)
                              …□□
    ■□□□□□□□□□□□□□□□
    □□□□□□□□□□□□□□□□
    □□…
            … (□×255 個)
                              …□□
    ■……

    以降、ブロック■を指示ブロックと呼ぶ。
    また、ブロック□は単にブロックと呼ぶ事にする。

  2.指示ブロックは 4B 整数 (LE) の集合である。
    0 番目の整数は後で説明する。

    n (1≦n≦255) 番目の整数は、
    その指示ブロックに続く 255 個のブロックについての情報を与える。
    つまり、指示ブロックの番号を i とすれば、
    指示ブロック内の n 番目の整数はブロック i+n についての情報を持つ。
    ・整数が 256 で割り切れない時
      整数は、ストリームのデータの続きが記録されている次のブロックの番号を意味する。
    ・整数が 0 の時
      そのブロックは使用されていない。
    ・整数が 0x100 の時
      そのブロックはストリームのデータの末端を保持している。続きのデータはない。
    ・整数が 0x1000 の時
    ・整数が 0x2000 の時
      そのブロックが 256 / 64 miniFAT cell のデータストリームを格納している事を示す。
    ・整数が 0x3000 の時
      そのブロックが heap (1B alignment 連続データのデータストリーム) を格納する物である事を示す。
    ・整数が 0x200 の時
      そのブロックがルートブロックである事を意味する。
      通常はブロック 1 がルートブロックになる。
      ルートブロックは一つのファイルに一つしかない。

    あるデータを取り出したければ、その開始ブロック番号とデータの長さが分かっていれば良い。
    開始ブロック番号を知っていれば、指示ブロックの中身を辿る事によって二番目のブロック、
    三番目のブロック、…を順次知る事が出来るからである。

    指示ブロック 0 の 0 番目の整数は、mwt 形式のブロック構造バージョンを表す。現状では 1。

  3.ルートブロックは以下の構造をしている

    ```
    struct RootBlock{
      int magic;   // mwt 形式の保証

      int RootDir_len; // "ルートディレクトリの中身" の長さ
      int RootDir_blk; // "ルートディレクトリの中身" の開始ブロック番号

      int Fat256_len;  // "fat256 セル指示"
      int Fat256_blk;  //
      int Dat256_len;  // "fat256 セル達が格納されているブロックの番号リスト"
      int Dat256_blk;  //
      int Fat64_len;   // "fat64 セル指示"
      int Fat64_blk;   //
      int Dat64_len;   // "fat256 セル達が格納されているブロックの番号リスト"
      int Dat64_blk;   //

      int HeapFreeNodeCount;
      int HeapFreeNodeLength;
      int HeapList_len; // "heap 表"
      int HeapList_blk; //
      int HeapData_len; // "heap ブロック番号リスト"
      int HeapData_blk; //

      // 作成日時
      // 更新日時
      // 読取日時
      // 属性 (rwx 読取日時記録 プロテクト quota etc.)
      // 著作権 etc.
      int reserved[239];
    };
    ```

  HeapList:

    ヒープ構造の実装方法
    * HRange (データの場所を示す為の構造) は一度作成したら移動しない
      HRange 配列を保持し、データの参照は HRange 番号を以て行う。
    * ガベージコレクションなどは、HRange を移動するのではなくて、
      HRange 内の参照先を変更する事によって行う。
    * ガベージコレクションのタイミングを計る為に、
      - 現在使用領域サイズ
      - 現在未使用領域サイズ
      - 現在未使用領域数
      等を保持する。
      - 未使用領域が使用領域より大きくなってきた時
      - 未使用領域の数が矢鱈多くなってきた時
      等にガベージコレクションを実行する
    * 未使用領域を結合する為には、
      未使用領域をスライドさせる必要がある。
      (未使用領域をスライドさせるというのは、要するに、隣り合う領域と位置を交換するという事である)
      その為には「現在の未使用領域の次の領域」
      が取得出来るようになっている必要がある。
      + その為の一つの方法は、領域を offset で sort したリストを保持する方法である。
        自分の次の領域を知りたかったら、先ず自分の offset でそのリストを二分探索し、
        次に、そのリストの次の要素を見て次の領域が分かる。
      + 或いは、別の方法としては、
        HRange 自体に自分の次の HRange 番号を常に保持するようにしておく事である。
        未使用領域をスライドさせる場合には、以下の手順が必要になる。
        目標: 1■,2□,3■,4■ → 1■,3■,2□,4■
        1. データを 3の場所から 2の場所にコピーする
        2. 1■->3■ 3■->2□ 2->4■ と繋ぎ変える。
        3. 更に 2 の操作を実行する為に、自分の前の HRange への参照を使っているので、
           1■<-3■ 3■<-2□ 2<-4■ と繋ぎ変える。

    ```
    struct HRange{
      int prevRange;
      int nextRange;
      int offset;
      int length; // 最上位ビットは未使用である事を示す
    };

    struct ExperimentalHeap{
      int firstRange;
      int emptyRange;

      std::vector<HRange> data;
      std::vector<int> freeRanges;

    public:
      ExperimentalHeap(){
        this->firstRange=-1;
        this->emptyRange=-1;
      }
      int alloc_handle(){
        int iR;
        if(this->emptyRange>=0){
          iR=this->emptyRange;
          this->emptyRange=this->data[iR]->nextRange;
        }else{
          iR=this->data->size();
          this->data->push_back(HRange());
        }
        return iR;
      }
      int alloc(int length){
        // HRange の確保
        int iR=alloc_handle();
        HRange& range(this->data[iR]);

        return iR;
      }
    };
    ```
